{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_diagonal(model_name):\n",
    "    dir = os.path.join(\"out\", model_name)\n",
    "\n",
    "    diagonal = json.load(open(os.path.join(dir, \"diagonal.json\"), \"r\"))\n",
    "    # subspace = json.load(\n",
    "    #     open(os.path.join(dir, \"subspace_IH_PTH_K40_largest.json\"), \"r\")\n",
    "    # )\n",
    "\n",
    "    return diagonal  # , subspace\n",
    "\n",
    "\n",
    "def find_most_similar_group(M, max_group_size):\n",
    "    # Apply the Hungarian algorithm to find the maximum weight matching\n",
    "    row_ind, col_ind = linear_sum_assignment(\n",
    "        -M\n",
    "    )  # Use -M to maximize instead of minimize\n",
    "\n",
    "    # Extract the matched pairs and their similarities\n",
    "    matched_pairs = [(i, j, M[i, j]) for i, j in zip(row_ind, col_ind)]\n",
    "\n",
    "    # Sort the matched pairs by similarity in descending order\n",
    "    matched_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Select the top pairs up to the desired group size\n",
    "    most_similar_group = matched_pairs[:max_group_size]\n",
    "\n",
    "    return most_similar_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(model_name, diagonal_cutoff=2, subspace_multipler_cutoff=1.5):\n",
    "    diagonal = load_diagonal(model_name)\n",
    "\n",
    "    # select by diagonal\n",
    "    ih, pth = [], []\n",
    "    for idx in range(len(diagonal)):\n",
    "        d = diagonal[idx]\n",
    "        if d[\"score\"] < diagonal_cutoff:\n",
    "            continue\n",
    "        if d[\"IH\"] not in ih:\n",
    "            ih.append(d[\"IH\"])\n",
    "\n",
    "        if d[\"PTH\"] not in pth:\n",
    "            pth.append(d[\"PTH\"])\n",
    "\n",
    "    print(model_name)\n",
    "    print(f\"DIAGONAL\\nIH[{len(ih)}]:{ih}\\nPTH[{len(pth)}]: {pth}\\n\" + \"-\" * 50)\n",
    "    save_dir = f\"checkpoints/{model_name}\"\n",
    "    torch.save(ih, f\"{save_dir}/IH_diagonal.pt\")\n",
    "    torch.save(pth, f\"{save_dir}/PTH_diagonal.pt\")\n",
    "\n",
    "    # # select by diagonal\n",
    "    # ih, pth = [], []\n",
    "    # baseline = subspace[0][\"baseline\"]\n",
    "    # subspace_cutoff = baseline * subspace_multipler_cutoff\n",
    "    # for idx in range(1, len(subspace)):\n",
    "    #     d = subspace[idx]\n",
    "    #     if d[\"score\"] < subspace_cutoff:\n",
    "    #         continue\n",
    "    #     if d[\"LH0\"] not in ih:\n",
    "    #         ih.append(d[\"LH0\"])\n",
    "    #     if d[\"LH1\"] not in pth:\n",
    "    #         pth.append(d[\"LH1\"])\n",
    "\n",
    "    # print(f\"SUBSPACE\\nIH[{len(ih)}]: {ih}\\nPTH[{len(pth)}]: {pth}\\n\" + \"-\" * 50)\n",
    "    # save_dir = f\"checkpoints/{model_name}\"\n",
    "    # torch.save(ih, f\"{save_dir}/IH_subspace.pt\")\n",
    "    # torch.save(pth, f\"{save_dir}/PTH_subspace.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt2\n",
      "DIAGONAL\n",
      "IH[23]:[[5, 1], [6, 9], [5, 5], [7, 2], [7, 10], [5, 8], [5, 0], [8, 1], [7, 11], [9, 6], [7, 1], [9, 4], [8, 10], [9, 9], [10, 1], [10, 2], [10, 11], [10, 10], [11, 9], [10, 6], [8, 3], [7, 7], [11, 7]]\n",
      "PTH[13]: [[4, 11], [5, 6], [8, 7], [6, 8], [6, 0], [9, 3], [3, 3], [7, 0], [5, 2], [1, 0], [2, 2], [4, 3], [3, 7]]\n",
      "--------------------------------------------------\n",
      "gpt2-xl\n",
      "DIAGONAL\n",
      "IH[18]:[[17, 6], [16, 21], [16, 3], [13, 0], [18, 0], [17, 14], [20, 0], [19, 18], [22, 20], [21, 3], [17, 1], [21, 20], [25, 19], [27, 23], [27, 1], [26, 20], [29, 14], [25, 16]]\n",
      "PTH[16]: [[15, 19], [12, 21], [13, 20], [14, 12], [16, 5], [11, 2], [9, 7], [14, 20], [10, 15], [13, 12], [7, 12], [16, 20], [26, 6], [17, 12], [10, 10], [25, 7]]\n",
      "--------------------------------------------------\n",
      "llama2-7b\n",
      "DIAGONAL\n",
      "IH[16]:[[6, 9], [6, 30], [7, 4], [8, 26], [7, 12], [7, 13], [6, 11], [8, 31], [6, 16], [11, 15], [7, 10], [7, 28], [12, 2], [11, 2], [16, 19], [12, 26]]\n",
      "PTH[4]: [[5, 15], [6, 5], [10, 3], [15, 11]]\n",
      "--------------------------------------------------\n",
      "gemma-7b\n",
      "DIAGONAL\n",
      "IH[7]:[[5, 0], [14, 15], [20, 1], [20, 13], [18, 13], [21, 1], [16, 1]]\n",
      "PTH[9]: [[3, 9], [13, 3], [19, 13], [3, 15], [2, 4], [17, 0], [1, 0], [13, 2], [15, 3]]\n",
      "--------------------------------------------------\n",
      "gemma2-9b\n",
      "DIAGONAL\n",
      "IH[24]:[[28, 6], [17, 5], [7, 1], [25, 13], [28, 2], [11, 2], [15, 2], [5, 1], [15, 3], [34, 14], [7, 0], [36, 6], [31, 7], [32, 5], [34, 12], [36, 12], [35, 0], [36, 7], [34, 13], [35, 14], [35, 1], [34, 15], [37, 14], [30, 9]]\n",
      "PTH[14]: [[27, 2], [16, 0], [6, 9], [24, 2], [10, 4], [14, 2], [10, 1], [3, 14], [3, 15], [14, 11], [31, 4], [31, 5], [3, 11], [6, 15]]\n",
      "--------------------------------------------------\n",
      "falcon-7b\n",
      "DIAGONAL\n",
      "IH[12]:[[5, 65], [5, 18], [5, 13], [5, 10], [5, 2], [5, 1], [5, 69], [5, 43], [5, 41], [5, 14], [5, 66], [5, 39]]\n",
      "PTH[1]: [[3, 38]]\n",
      "--------------------------------------------------\n",
      "mistral-7b\n",
      "DIAGONAL\n",
      "IH[6]:[[12, 6], [12, 4], [12, 7], [18, 2], [18, 1], [18, 3]]\n",
      "PTH[2]: [[11, 17], [17, 22]]\n",
      "--------------------------------------------------\n",
      "olmo-7b\n",
      "DIAGONAL\n",
      "IH[6]:[[27, 14], [15, 15], [24, 7], [2, 28], [2, 10], [26, 17]]\n",
      "PTH[9]: [[26, 25], [14, 30], [14, 18], [23, 24], [1, 7], [24, 3], [25, 6], [1, 15], [26, 30]]\n",
      "--------------------------------------------------\n",
      "llama3-8b\n",
      "DIAGONAL\n",
      "IH[21]:[[15, 28], [15, 30], [8, 1], [15, 1], [5, 11], [5, 8], [5, 10], [5, 9], [16, 20], [16, 23], [2, 22], [2, 23], [2, 25], [2, 12], [2, 21], [10, 14], [2, 26], [27, 7], [27, 5], [2, 20], [27, 6]]\n",
      "PTH[8]: [[14, 26], [7, 2], [4, 13], [7, 1], [4, 12], [1, 20], [9, 11], [25, 20]]\n",
      "--------------------------------------------------\n",
      "pythia-7b\n",
      "DIAGONAL\n",
      "IH[26]:[[7, 26], [7, 2], [7, 1], [6, 30], [8, 11], [8, 17], [4, 18], [8, 4], [6, 13], [7, 20], [8, 29], [4, 0], [8, 24], [15, 17], [9, 30], [7, 30], [9, 25], [5, 21], [11, 1], [5, 1], [10, 28], [15, 21], [5, 29], [10, 13], [10, 30], [10, 1]]\n",
      "PTH[7]: [[6, 9], [5, 10], [3, 7], [3, 23], [14, 3], [6, 23], [11, 19]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\n",
    "    \"gpt2\",\n",
    "    \"gpt2-xl\",\n",
    "    \"llama2-7b\",\n",
    "    \"gemma-7b\",\n",
    "    \"gemma2-9b\",\n",
    "    \"falcon-7b\",\n",
    "    \"mistral-7b\",\n",
    "    \"olmo-7b\",\n",
    "    \"llama3-8b\",\n",
    "    \"pythia-7b\",\n",
    "]:\n",
    "    select(model_name, diagonal_cutoff=2.3, subspace_multipler_cutoff=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually insert\n",
    "head_subset = {\n",
    "    \"llama2-7b\": {\n",
    "        \"IH\": [\n",
    "            [11, 15],\n",
    "            [7, 4],\n",
    "            [7, 12],\n",
    "            [17, 22],\n",
    "            [8, 31],\n",
    "            [7, 13],\n",
    "            [7, 10],\n",
    "            [13, 23],\n",
    "        ],\n",
    "        \"PTH\": [\n",
    "            [5, 15],\n",
    "            [6, 5],\n",
    "            [10, 25],\n",
    "            [5, 16],\n",
    "        ],\n",
    "    },\n",
    "    \"falcon-7b\": {\n",
    "        \"IH\": [\n",
    "            [5, 41],\n",
    "            [5, 2],\n",
    "            [5, 18],\n",
    "            [5, 52],\n",
    "            [5, 65],\n",
    "            [5, 10],\n",
    "            [5, 1],\n",
    "            [5, 69],\n",
    "            [5, 13],\n",
    "            [5, 43],\n",
    "            [5, 14],\n",
    "            [5, 59],\n",
    "            [5, 39],\n",
    "            [5, 66],\n",
    "            [5, 49],\n",
    "            [5, 63],\n",
    "            [5, 33],\n",
    "            [5, 7],\n",
    "            [5, 70],\n",
    "        ],\n",
    "        \"PTH\": [[3, 38], [2, 40], [2, 21]],\n",
    "    },\n",
    "    \"olmo-7b\": {\n",
    "        \"IH\": [[27, 14], [26, 17], [15, 15], [24, 7], [30, 13]],\n",
    "        \"PTH\": [[26, 25], [24, 3], [14, 18], [25, 6], [28, 13], [26, 30]],\n",
    "    },\n",
    "    \"mistral-7b\": {\n",
    "        \"IH\": [\n",
    "            [18, 0],\n",
    "            [18, 2],\n",
    "            [18, 3],\n",
    "            [12, 4],\n",
    "            [18, 1],\n",
    "            [26, 6],\n",
    "            [20, 29],\n",
    "            [20, 30],\n",
    "            [20, 28],\n",
    "            [22, 4],\n",
    "            [26, 5],\n",
    "            [21, 1],\n",
    "        ],\n",
    "        \"PTH\": [[11, 17], [17, 22], [24, 8], [29, 4], [6, 24]],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, heads in head_subset.items():\n",
    "    ih = heads[\"IH\"]\n",
    "    pth = heads[\"PTH\"]\n",
    "    save_dir = f\"checkpoints/{model_name}\"\n",
    "    torch.save(ih, f\"{save_dir}/IH_subset.pt\")\n",
    "    torch.save(pth, f\"{save_dir}/PTH_subset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
